num_NAS(train)
# create a new column 'greater_50k that takes a value of 1 if the income is greater than 50k and 0 otherwise
train$greater_50k <- ifelse(train$income == ">50K", 1, 0)
test$greater_50k <- ifelse(test$income == ">50K.", 1, 0)
# proportion of observations in each Native Country
prop.table(table(train$native_country, useNA = 'always'))[order(table(train$native_country), decreasing = TRUE)][1:5]
# since the native country of 89.5% of observations is United States create a new variable 'is_UnitedStates' that takes a value of 1 if the observation is from the United States and 0 otherwise.
train$is_UnitedStates <- ifelse(train$native_country == 'United-States', 1, 0)
test$is_UnitedStates <- ifelse(test$native_country == 'United-States', 1, 0)
train$is_UnitedStates[is.na(train$is_UnitedStates)] <- 1
test$is_UnitedStates[is.na(test$is_UnitedStates)] <- 1
head(train)
# summary statistics of all the variables
summary(train)
# Replace NA values in workclass, occupation and Native Country by the maximum occurring values.
# workclass
train$workclass[is.na(train$workclass)] <- return_max(train$workclass)
test$workclass[is.na(test$workclass)] <- return_max(train$workclass)
# occupation
train$occupation[is.na(train$occupation)] <- return_max(train$occupation)
test$occupation[is.na(test$occupation)] <- return_max(train$occupation)
# Native Country
train$native_country[is.na(train$native_country)] <- return_max(train$native_country)
test$native_country[is.na(test$native_country)] <- return_max(train$native_country)
# Histogram with a density curve
plot_histogram(train, 'age')
# boxplot comparing the distributions across the two levels of income
plot_boxplot(train, 'income', 'age')
# Faceted historgram by income
plot_faceted_histogram(train, 'age', 'income')
plot_histogram(train, 'fnlwgt')
plot_boxplot(train, 'income', 'fnlwgt')
plot_faceted_histogram(train, 'fnlwgt', 'income')
# Histogram with a density curve
plot_histogram(train, 'capital_gain')
plot_boxplot(train, 'income', 'capital_gain')
plot_faceted_histogram(train, 'capital_gain', 'income')
# Histogram with a density curve
plot_histogram(train, 'capital_loss')
plot_boxplot(train, 'income', 'capital_loss')
plot_faceted_histogram(train, 'capital_loss', 'income')
# Histogram with a density curve
plot_histogram(train, 'hours_per_week')
plot_boxplot(train, 'income', 'hours_per_week')
plot_faceted_histogram(train, 'hours_per_week', 'income')
# Univariate analysis - count of each level in workclass
plot_bar_plot_count(train, 'workclass')
# proportion of observations that have income greater than 50k for each level
plot_bar_plot_prop(train, 'workclass', 'greater_50k')
# stacked bar plot - for a given level shows the number of obervations belonging to each income level
plot_bar_plot_stacked(train, 'workclass', 'income')
plot_bar_plot_count(train, 'education')
plot_bar_plot_prop(train, 'education', 'greater_50k')
plot_bar_plot_stacked(train, 'education', 'income')
plot_bar_plot_count(train, 'marital_status')
plot_bar_plot_prop(train, 'marital_status', 'greater_50k')
plot_bar_plot_stacked(train, 'marital_status', 'income')
plot_bar_plot_count(train, 'occupation')
plot_bar_plot_prop(train, 'occupation', 'greater_50k')
plot_bar_plot_stacked(train, 'occupation', 'income')
plot_bar_plot_count(train, 'relationship')
plot_bar_plot_prop(train, 'relationship', 'greater_50k')
plot_bar_plot_stacked(train, 'relationship', 'income')
plot_bar_plot_count(train, 'race')
plot_bar_plot_prop(train, 'race', 'greater_50k')
plot_bar_plot_stacked(train, 'race', 'income')
plot_bar_plot_count(train, 'sex')
plot_bar_plot_prop(train, 'sex', 'greater_50k')
plot_bar_plot_stacked(train, 'sex', 'income')
# mosaic plot - shows the proportions of observations in each level of the independent variable for each level of the dependent variable
mosaicplot(income ~ sex, data = train, main = '')
plot_bar_plot_count(train, 'is_UnitedStates')
plot_bar_plot_prop(train, 'is_UnitedStates', 'greater_50k')
plot_bar_plot_stacked(train, 'is_UnitedStates', 'income')
mosaicplot(income ~ is_UnitedStates, data = train, main = '')
# correlation plot of numeric variables
numeric_variables <- c('age', 'fnlwgt', "capital_gain", "capital_loss", "hours_per_week")
corrplot(cor(train[numeric_variables]), method = "number")
# remove the columns that are not required
train <- train %>%
select(-education, -native_country, -income)
test <- test %>%
select(-education, -native_country, -income)
summary(train)
# one hot encode the categorical variables
dummy <- dummyVars(greater_50k ~ ., data = train)
train_dummies <- data.frame(predict(dummy, train))
test_dummies <- data.frame(predict(dummy, test))
head(train_dummies)
# add the dependent variable back to the dataframe
train_dummies$greater_50k <- train$greater_50k
test_dummies$greater_50k <- test$greater_50k
head(train_dummies)
# convert education_num to character since it is not be normalised/scaled
train_dummies$education_num <- as.character(train_dummies$education_num)
test_dummies$education_num <- as.character(test_dummies$education_num)
# min max scaler to scale variables between 1 and 0
# intialize and learn the parameters of the scaled object
scaler <- preProcess(train_dummies, method = 'range')
# scale the training set
train_scaled <- predict(scaler, train_dummies)
# scale the test set
test_scaled <- predict(scaler, test_dummies)
# all numeric variables have been scaled between 0 and 1
summary(train_scaled)
# label encode education_num
train_scaled$education_num <- as.numeric(train_scaled$education_num)
test_scaled$education_num <- as.numeric(test_scaled$education_num)
head(train_scaled)
model_glm <- glm(greater_50k ~ .- 1, data = train_scaled, family = binomial(link = 'logit'))
summary(model_glm)
source('libraries.R')
source('functions.R')
col_names <- c('age', 'workclass', 'fnlwgt', 'education', 'education_num', 'marital_status',
'occupation', 'relationship', 'race', 'sex', 'capital_gain', 'capital_loss',
'hours_per_week', 'native_country', 'income')
# read the training data
train <- read_csv('data/adult_train.csv', na = '?', col_names = col_names, skip = 1)
# read the testing data
test <- read_csv('data/adult_test',
na = '?',
col_names = col_names)
# take a peak at the data and the data type of each variable
str(data.frame(train))
# check the number of NAs in each column
num_NAS(train)
# create a new column 'greater_50k that takes a value of 1 if the income is greater than 50k and 0 otherwise
train$greater_50k <- ifelse(train$income == ">50K", 1, 0)
test$greater_50k <- ifelse(test$income == ">50K.", 1, 0)
# proportion of observations in each Native Country
prop.table(table(train$native_country, useNA = 'always'))[order(table(train$native_country), decreasing = TRUE)][1:5]
# since the native country of 89.5% of observations is United States create a new variable 'is_UnitedStates' that takes a value of 1 if the observation is from the United States and 0 otherwise.
train$is_UnitedStates <- ifelse(train$native_country == 'United-States', 1, 0)
test$is_UnitedStates <- ifelse(test$native_country == 'United-States', 1, 0)
train$is_UnitedStates[is.na(train$is_UnitedStates)] <- 1
test$is_UnitedStates[is.na(test$is_UnitedStates)] <- 1
head(train)
# summary statistics of all the variables
summary(train)
# Replace NA values in workclass, occupation and Native Country by the maximum occurring values.
# workclass
train$workclass[is.na(train$workclass)] <- return_max(train$workclass)
test$workclass[is.na(test$workclass)] <- return_max(train$workclass)
# occupation
train$occupation[is.na(train$occupation)] <- return_max(train$occupation)
test$occupation[is.na(test$occupation)] <- return_max(train$occupation)
# Native Country
train$native_country[is.na(train$native_country)] <- return_max(train$native_country)
test$native_country[is.na(test$native_country)] <- return_max(train$native_country)
# Histogram with a density curve
plot_histogram(train, 'age')
# boxplot comparing the distributions across the two levels of income
plot_boxplot(train, 'income', 'age')
# Faceted historgram by income
plot_faceted_histogram(train, 'age', 'income')
plot_histogram(train, 'fnlwgt')
plot_boxplot(train, 'income', 'fnlwgt')
plot_faceted_histogram(train, 'fnlwgt', 'income')
# Histogram with a density curve
plot_histogram(train, 'capital_gain')
plot_boxplot(train, 'income', 'capital_gain')
plot_faceted_histogram(train, 'capital_gain', 'income')
# Histogram with a density curve
plot_histogram(train, 'capital_loss')
plot_boxplot(train, 'income', 'capital_loss')
plot_faceted_histogram(train, 'capital_loss', 'income')
# Histogram with a density curve
plot_histogram(train, 'hours_per_week')
plot_boxplot(train, 'income', 'hours_per_week')
plot_faceted_histogram(train, 'hours_per_week', 'income')
# Univariate analysis - count of each level in workclass
plot_bar_plot_count(train, 'workclass')
# proportion of observations that have income greater than 50k for each level
plot_bar_plot_prop(train, 'workclass', 'greater_50k')
# stacked bar plot - for a given level shows the number of obervations belonging to each income level
plot_bar_plot_stacked(train, 'workclass', 'income')
plot_bar_plot_count(train, 'education')
plot_bar_plot_prop(train, 'education', 'greater_50k')
plot_bar_plot_stacked(train, 'education', 'income')
plot_bar_plot_count(train, 'marital_status')
plot_bar_plot_prop(train, 'marital_status', 'greater_50k')
plot_bar_plot_stacked(train, 'marital_status', 'income')
plot_bar_plot_count(train, 'occupation')
plot_bar_plot_prop(train, 'occupation', 'greater_50k')
plot_bar_plot_stacked(train, 'occupation', 'income')
plot_bar_plot_count(train, 'relationship')
plot_bar_plot_prop(train, 'relationship', 'greater_50k')
plot_bar_plot_stacked(train, 'relationship', 'income')
plot_bar_plot_count(train, 'race')
plot_bar_plot_prop(train, 'race', 'greater_50k')
plot_bar_plot_stacked(train, 'race', 'income')
plot_bar_plot_count(train, 'sex')
plot_bar_plot_prop(train, 'sex', 'greater_50k')
plot_bar_plot_stacked(train, 'sex', 'income')
# mosaic plot - shows the proportions of observations in each level of the independent variable for each level of the dependent variable
mosaicplot(income ~ sex, data = train, main = '')
plot_bar_plot_count(train, 'is_UnitedStates')
plot_bar_plot_prop(train, 'is_UnitedStates', 'greater_50k')
plot_bar_plot_stacked(train, 'is_UnitedStates', 'income')
mosaicplot(income ~ is_UnitedStates, data = train, main = '')
# correlation plot of numeric variables
numeric_variables <- c('age', 'fnlwgt', "capital_gain", "capital_loss", "hours_per_week")
corrplot(cor(train[numeric_variables]), method = "number")
# remove the columns that are not required
train <- train %>%
select(-education, -native_country, -income)
test <- test %>%
select(-education, -native_country, -income)
summary(train)
# one hot encode the categorical variables
dummy <- dummyVars(greater_50k ~ ., data = train)
train_dummies <- data.frame(predict(dummy, train))
test_dummies <- data.frame(predict(dummy, test))
head(train_dummies)
# add the dependent variable back to the dataframe
train_dummies$greater_50k <- train$greater_50k
test_dummies$greater_50k <- test$greater_50k
head(train_dummies)
# convert education_num to character since it is not be normalised/scaled
train_dummies$education_num <- as.character(train_dummies$education_num)
test_dummies$education_num <- as.character(test_dummies$education_num)
# min max scaler to scale variables between 1 and 0
# intialize and learn the parameters of the scaled object
scaler <- preProcess(train_dummies, method = 'range')
# scale the training set
train_scaled <- predict(scaler, train_dummies)
# scale the test set
test_scaled <- predict(scaler, test_dummies)
# all numeric variables have been scaled between 0 and 1
summary(train_scaled)
# label encode education_num
train_scaled$education_num <- as.numeric(train_scaled$education_num)
test_scaled$education_num <- as.numeric(test_scaled$education_num)
head(train_scaled)
model_glm <- glm(greater_50k ~ .- 1, data = train_scaled, family = binomial(link = 'logit'))
# check the regression coefficients and the significance
summary(model_glm)
confusionMatrix()
>confusionMatrix()
?confusionMatrix()
# predict on the test set
Y_pred <- predict(model_glm, newdata = test_scaled, type = 'response')
# select a probability threshold
thresh <- 0.5
# values greater than thresh are assigned 1 else 0
Y_pred_vals <- ifelse(Y_pred > thresh, 1, 0)
# confusion matrix
caret::confusionMatrix(data = Y_pred_vals, reference = test_scaled$greater_50k)
# predict on the test set
Y_pred <- predict(model_glm, newdata = test_scaled, type = 'response')
# select a probability threshold
thresh <- 0.5
# values greater than thresh are assigned 1 else 0
Y_pred_vals <- ifelse(Y_pred > thresh, 1, 0)
# confusion matrix
caret::confusionMatrix(data = Y_pred_vals, reference = test_scaled$greater_50k, positive = '1', mode =  "prec_recall")
# predict on the test set
Y_pred <- predict(model_glm, newdata = test_scaled, type = 'response')
# select a probability threshold
thresh <- 0.5
# values greater than thresh are assigned 1 else 0
Y_pred_vals <- ifelse(Y_pred > thresh, 1, 0)
# confusion matrix and some important metrics - precision, recall and kappa score
caret::confusionMatrix(data = Y_pred_vals, reference = test_scaled$greater_50k, positive = '1', mode =  "everything")
library('pROC')
# AUC
auc(test_scaled$greater_50k, Y_pred)
# AUC
pROC::auc(test_scaled$greater_50k, Y_pred)
# plot the auc curve
rocobj <- pROC::roc(test_scaled$greater_50k, Y_pred)
# plot the auc curve
rocobj <- pROC::roc(test_scaled$greater_50k, Y_pred)
plot(rocobj)
checkInstallLoad('ROCR')
?prediction
pred1 <- prediction(Y_pred, test_scaled$greater_50k)
perf1 <- performance(pred1,"tpr","fpr")
plot(perf1)
pred1 <- ROCR::prediction(Y_pred, test_scaled$greater_50k)
perf1 <- ROCR::performance(pred1,"tpr","fpr")
plot(perf1)
checkInstallLoad('ROSE')
names(train_scaled)
train_scaled %>% select(-greater_50k)
train_scaled[,-"greater_50k"]
train_scaled[,-c("greater_50k")]
train_scaled[-c("greater_50k")]
# Since there is some amount of imbalance in the number of observations belonging to each class, (75% of the observations are classifed as having income less than 50k), the minority class viz. the income greater than 50k can be oversampled.
# create a temporary dataframe that excludes the dependent variable
train_temp_df <- train_scaled %>% select(-greater_50k)
set.seed(1)
upSampledTrain <- caret::upSample(x = train_temp_df, y = train_scaled$greater_50k)
# Since there is some amount of imbalance in the number of observations belonging to each class, (75% of the observations are classifed as having income less than 50k), the minority class viz. the income greater than 50k can be oversampled.
# create a temporary dataframe that excludes the dependent variable
train_temp_df <- train_scaled %>% select(-greater_50k)
set.seed(1)
upSampledTrain <- caret::upSample(x = train_temp_df, y = factor(train_scaled$greater_50k))
# Since there is some amount of imbalance in the number of observations belonging to each class, (75% of the observations are classifed as having income less than 50k), the minority class viz. the income greater than 50k can be oversampled.
# create a temporary dataframe that excludes the dependent variable
train_temp_df <- train_scaled %>% select(-greater_50k)
set.seed(1)
upSampledTrain <- caret::upSample(x = train_temp_df,
y = factor(train_scaled$greater_50k),
yname = 'greater_50k')
# Since there is some amount of imbalance in the number of observations belonging to each class, (75% of the observations are classifed as having income less than 50k), the minority class viz. the income greater than 50k can be oversampled.
# create a temporary dataframe that excludes the dependent variable
# train_temp_df <- train_scaled %>% select(-greater_50k)
set.seed(1)
upSampledTrain <- caret::upSample(x = train_scaled %>% select(-greater_50k),
y = factor(train_scaled$greater_50k),
yname = 'greater_50k')
table(upSampledTrain$greater_50k)
# check the distribution of each class
prop.table(table(train_scaled$greater_50k))
# check new distribution of classes in the upsampled set
prop.table(table(upSampledTrain$greater_50k))
# fit a new logistic regression model on the oversampled data
model_glm_resamp <- glm(greater_50k ~ . -1,
data = upSampledTrain,
family = binomial(link = 'logit'))
Y_pred_resamp <- predict(model_glm_resamp, newdata = test_scaled, type = 'response') # test set remains the same
thresh <- 0.5
Y_pred_resamp_vals <- ifelse(Y_pred_resamp > thresh, 1, 0)
# check the score on the original test set. Note that the observations from test set were not oversampled
caret::confusionMatrix(data = Y_pred_resamp_vals, reference = test_scaled$greater_50k, positive = '1', mode =  "everything")
source('libraries.R')
source('functions.R')
col_names <- c('age', 'workclass', 'fnlwgt', 'education', 'education_num', 'marital_status',
'occupation', 'relationship', 'race', 'sex', 'capital_gain', 'capital_loss',
'hours_per_week', 'native_country', 'income')
# read the training data
train <- read_csv('data/adult_train.csv', na = '?', col_names = col_names, skip = 1)
# read the testing data
test <- read_csv('data/adult_test',
na = '?',
col_names = col_names)
# take a peak at the data and the data type of each variable
str(data.frame(train))
# check the number of NAs in each column
num_NAS(train)
# create a new column 'greater_50k that takes a value of 1 if the income is greater than 50k and 0 otherwise
train$greater_50k <- ifelse(train$income == ">50K", 1, 0)
test$greater_50k <- ifelse(test$income == ">50K.", 1, 0)
# proportion of observations in each Native Country
prop.table(table(train$native_country, useNA = 'always'))[order(table(train$native_country), decreasing = TRUE)][1:5]
# since the native country of 89.5% of observations is United States create a new variable 'is_UnitedStates' that takes a value of 1 if the observation is from the United States and 0 otherwise.
train$is_UnitedStates <- ifelse(train$native_country == 'United-States', 1, 0)
test$is_UnitedStates <- ifelse(test$native_country == 'United-States', 1, 0)
train$is_UnitedStates[is.na(train$is_UnitedStates)] <- 1
test$is_UnitedStates[is.na(test$is_UnitedStates)] <- 1
head(train)
# summary statistics of all the variables
summary(train)
# Replace NA values in workclass, occupation and Native Country by the maximum occurring values.
# workclass
train$workclass[is.na(train$workclass)] <- return_max(train$workclass)
test$workclass[is.na(test$workclass)] <- return_max(train$workclass)
# occupation
train$occupation[is.na(train$occupation)] <- return_max(train$occupation)
test$occupation[is.na(test$occupation)] <- return_max(train$occupation)
# Native Country
train$native_country[is.na(train$native_country)] <- return_max(train$native_country)
test$native_country[is.na(test$native_country)] <- return_max(train$native_country)
# Histogram with a density curve
plot_histogram(train, 'age')
# boxplot comparing the distributions across the two levels of income
plot_boxplot(train, 'income', 'age')
# Faceted historgram by income
plot_faceted_histogram(train, 'age', 'income')
plot_histogram(train, 'fnlwgt')
plot_boxplot(train, 'income', 'fnlwgt')
plot_faceted_histogram(train, 'fnlwgt', 'income')
# Histogram with a density curve
plot_histogram(train, 'capital_gain')
plot_boxplot(train, 'income', 'capital_gain')
plot_faceted_histogram(train, 'capital_gain', 'income')
# Histogram with a density curve
plot_histogram(train, 'capital_loss')
plot_boxplot(train, 'income', 'capital_loss')
plot_faceted_histogram(train, 'capital_loss', 'income')
# Histogram with a density curve
plot_histogram(train, 'hours_per_week')
plot_boxplot(train, 'income', 'hours_per_week')
plot_faceted_histogram(train, 'hours_per_week', 'income')
# Univariate analysis - count of each level in workclass
plot_bar_plot_count(train, 'workclass')
# proportion of observations that have income greater than 50k for each level
plot_bar_plot_prop(train, 'workclass', 'greater_50k')
# stacked bar plot - for a given level shows the number of obervations belonging to each income level
plot_bar_plot_stacked(train, 'workclass', 'income')
plot_bar_plot_count(train, 'education')
plot_bar_plot_prop(train, 'education', 'greater_50k')
plot_bar_plot_stacked(train, 'education', 'income')
plot_bar_plot_count(train, 'marital_status')
plot_bar_plot_prop(train, 'marital_status', 'greater_50k')
plot_bar_plot_stacked(train, 'marital_status', 'income')
plot_bar_plot_count(train, 'occupation')
plot_bar_plot_prop(train, 'occupation', 'greater_50k')
plot_bar_plot_stacked(train, 'occupation', 'income')
plot_bar_plot_count(train, 'relationship')
plot_bar_plot_prop(train, 'relationship', 'greater_50k')
plot_bar_plot_stacked(train, 'relationship', 'income')
plot_bar_plot_count(train, 'race')
plot_bar_plot_prop(train, 'race', 'greater_50k')
plot_bar_plot_stacked(train, 'race', 'income')
plot_bar_plot_count(train, 'sex')
plot_bar_plot_prop(train, 'sex', 'greater_50k')
plot_bar_plot_stacked(train, 'sex', 'income')
# mosaic plot - shows the proportions of observations in each level of the independent variable for each level of the dependent variable
mosaicplot(income ~ sex, data = train, main = '')
plot_bar_plot_count(train, 'is_UnitedStates')
plot_bar_plot_prop(train, 'is_UnitedStates', 'greater_50k')
plot_bar_plot_stacked(train, 'is_UnitedStates', 'income')
mosaicplot(income ~ is_UnitedStates, data = train, main = '')
# correlation plot of numeric variables
numeric_variables <- c('age', 'fnlwgt', "capital_gain", "capital_loss", "hours_per_week")
corrplot(cor(train[numeric_variables]), method = "number")
# remove the columns that are not required
train <- train %>%
select(-education, -native_country, -income)
test <- test %>%
select(-education, -native_country, -income)
summary(train)
# one hot encode the categorical variables
dummy <- dummyVars(greater_50k ~ ., data = train)
train_dummies <- data.frame(predict(dummy, train))
test_dummies <- data.frame(predict(dummy, test))
head(train_dummies)
# add the dependent variable back to the dataframe
train_dummies$greater_50k <- train$greater_50k
test_dummies$greater_50k <- test$greater_50k
head(train_dummies)
# convert education_num to character since it is not be normalised/scaled
train_dummies$education_num <- as.character(train_dummies$education_num)
test_dummies$education_num <- as.character(test_dummies$education_num)
# min max scaler to scale variables between 1 and 0
# intialize and learn the parameters of the scaled object
scaler <- preProcess(train_dummies, method = 'range')
# scale the training set
train_scaled <- predict(scaler, train_dummies)
# scale the test set
test_scaled <- predict(scaler, test_dummies)
# all numeric variables have been scaled between 0 and 1
summary(train_scaled)
# label encode education_num
train_scaled$education_num <- as.numeric(train_scaled$education_num)
test_scaled$education_num <- as.numeric(test_scaled$education_num)
head(train_scaled)
model_glm <- glm(greater_50k ~ .- 1, data = train_scaled, family = binomial(link = 'logit'))
# check the regression coefficients and the significance
summary(model_glm)
# predict on the test set
Y_pred <- predict(model_glm, newdata = test_scaled, type = 'response')
# select a probability threshold
thresh <- 0.5
# values greater than thresh are assigned 1 else 0
Y_pred_vals <- ifelse(Y_pred > thresh, 1, 0)
# confusion matrix and some important metrics - precision, recall, sensitivity, specificity and kappa score
caret::confusionMatrix(data = Y_pred_vals, reference = test_scaled$greater_50k, positive = '1', mode =  "everything")
# AUC
pROC::auc(test_scaled$greater_50k, Y_pred)
# plot the AUC curve
pred1 <- ROCR::prediction(Y_pred, test_scaled$greater_50k)
perf1 <- ROCR::performance(pred1,"tpr","fpr")
plot(perf1)
# check the distribution of each class
prop.table(table(train_scaled$greater_50k))
# Since there is some amount of imbalance in the number of observations belonging to each class, (75% of the observations are classifed as having income less than 50k), the minority class viz. the income greater than 50k can be oversampled.
# create a temporary dataframe that excludes the dependent variable
# train_temp_df <- train_scaled %>% select(-greater_50k)
set.seed(1)
upSampledTrain <- caret::upSample(x = train_scaled %>% select(-greater_50k),
y = factor(train_scaled$greater_50k),
yname = 'greater_50k')
# check new distribution of classes in the upsampled set
prop.table(table(upSampledTrain$greater_50k))
# fit a new logistic regression model on the oversampled data
model_glm_resamp <- glm(greater_50k ~ . -1,
data = upSampledTrain,
family = binomial(link = 'logit'))
Y_pred_resamp <- predict(model_glm_resamp, newdata = test_scaled, type = 'response') # test set remains the same
thresh <- 0.5
Y_pred_resamp_vals <- ifelse(Y_pred_resamp > thresh, 1, 0)
# check the score on the original test set. Note that the observations from test set were not oversampled
caret::confusionMatrix(data = Y_pred_resamp_vals, reference = test_scaled$greater_50k, positive = '1', mode =  "everything")
# load the data
df_groceries <- read.csv("data/groceries.csv")
head(df_groceries)
# data cleaning and manipulations
# make sure that the Member numbers are of numeric data type and then sort the dataframe based on the Member_number.
df_sorted <- df_groceries[order(df_groceries$Member_number),]
df_sorted$Member_number <- as.numeric(df_sorted$Member_number)
# convert the dataframe into transactions format such that all the items bought at the same time in one row.
library(plyr)
# convert the dataframe into basket format, based on the Member_number and Date of transaction
df_itemList <- ddply(df_groceries,c("Member_number","Date"),
function(df1) paste(df1$itemDescription, collapse = ","))
# delete date and member_number
df_itemList$Member_number <- NULL
df_itemList$Date <- NULL
colnames(df_itemList) <- c("itemList")
# write.csv(df_itemList,"ItemList.csv", row.names = TRUE)
# txn = read.transactions(file="ItemList.csv", rm.duplicates= TRUE, format="basket",sep=",",cols=1);
# add the row numbers such that they can be used as transaction IDs
df_itemList$id <- 1:nrow(df_itemList)
library(arules)
# coerce the data frame to class transactions
txn = as(split(df_itemList[,"itemList"], df_itemList[,"id"]), "transactions")
basket_rules <- apriori(txn, parameter = list(sup = 0, conf = 0, target="rules"));
?inspect
arules::inspect(basket_rules[1:5])
